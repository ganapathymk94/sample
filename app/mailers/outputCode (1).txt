import java.io.File;
import java.time.Instant;
import java.time.ZoneId;
import java.time.ZonedDateTime;
import java.time.format.DateTimeFormatter;
import java.util.Map;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import java.io.IOException;
import java.util.Properties;
import java.util.Arrays;
import java.util.List;
import java.util.ArrayList;
import java.util.stream.Collectors;
import java.nio.file.Paths;
import java.nio.file.Files;

public class kafkautil {
    private static final Logger logger = LoggerFactory.getLogger(kafkautil.class);
    private KafkaConsumer<String, String> defconsumer;
    private String KAFKA_IP;
    private String TOPIC;
    private String OUTDIR;
    private String OUTFILE;

    public kafkautil(String propfile, String outdir) {
        Properties props = new Properties();
        try {
            props.load(Files.newInputStream(Paths.get(propfile)));
            KAFKA_IP = props.getProperty("kafka.bootstrap.servers");
            TOPIC = props.getProperty("kafka.topic");
            OUTDIR = outdir;
            OUTFILE = props.getProperty("output.file");

            props.put("bootstrap.servers", KAFKA_IP);
            props.put("group.id", "test-consumer-group");
            props.put("enable.auto.commit", "false");
            props.put("auto.commit.interval.ms", "1000");
            props.put("session.timeout.ms", "30000");
            props.put("key.deserializer", StringDeserializer.class.getName());
            props.put("value.deserializer", StringDeserializer.class.getName());

            defconsumer = new KafkaConsumer<>(props);
        } catch (IOException e) {
            logger.error("Error loading properties file: {}", e.getMessage());
        }
    }

    private long getepoch(String dateStr) {
        DateTimeFormatter formatter = DateTimeFormatter.ISO_DATE_TIME.withZone(ZoneId.systemDefault());
        ZonedDateTime zdt = ZonedDateTime.parse(dateStr, formatter);
        return zdt.toEpochSecond();
    }

    private List<TopicPartition> getOffsets(long start, long end) {
        List<TopicPartition> partitions = defconsumer.assignment();
        List<TopicPartition> result = new ArrayList<>();
        for (TopicPartition partition : partitions) {
            long startOffset = defconsumer.offsetsForTimestamps(Map.of(partition, start)).get(partition).offset();
            long endOffset = defconsumer.offsetsForTimestamps(Map.of(partition, end)).get(partition).offset();
            result.add(new TopicPartition(partition.topic(), partition.partition()));
            defconsumer.seek(partition, startOffset);
            defconsumer.seek(partition, endOffset);
        }
        return result;
    }

    private List<String> consumeMsg(List<TopicPartition> partitions) {
        List<String> messages = new ArrayList<>();
        defconsumer.assign(partitions);
        ConsumerRecords<String, String> records = defconsumer.poll(1000);
        for (ConsumerRecord<String, String> record : records) {
            messages.add(record.value());
        }
        return messages;
    }

    public int doWork(String START_DATE, String END_DATE) {
        long start = getepoch(START_DATE) * 1000;
        long end = getepoch(END_DATE) * 1000;
        logger.info("Kafka Message Consuming between {} ({}) : {} ({})", START_DATE, start, END_DATE, end);
        List<TopicPartition> startOffsets = getOffsets(start, end);
        List<String> messages = consumeMsg(startOffsets);
        File file = new File(OUTDIR, OUTFILE);
        Files.write(file.toPath(), messages);
        logger.info("\nTotal {} messages written to {}/{}", messages.size(), OUTDIR, OUTFILE);
        return messages.size();
    }

    public void close() {
        try {
            defconsumer.close();
        } catch (Exception e) {
            logger.error(e.getMessage());
        }
    }
}

public class Main {
    public static void main(String[] args) {
        String startts = System.getenv().getOrDefault("START_DATE", "2022-12-11T15:00:12");
        String endts = System.getenv().getOrDefault("END_DATE", "2022-12-11T16:10:12");
        String basedir = System.getProperty("user.dir");
        String propfile = basedir + "/my.prop";
        String outdir = basedir + "/output";
        File outputDir = new File(outdir);
        if (!outputDir.exists()) {
            outputDir.mkdirs();
        }
        kafkautil k = new kafkautil(propfile, outdir);
        int count = k.doWork(startts, endts);
        k.close();
    }
}

